{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensor2Tensor Intro my first trial",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asakoRaven/Colab/blob/master/Tensor2Tensor_Intro_my_first_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "odi2vIMHC3Rm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Welcome to the [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor) Colab\n",
        "\n",
        "Tensor2Tensor, or T2T for short, is a library of deep learning models and datasets designed to make deep learning more accessible and [accelerate ML research](https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html). T2T is actively used and maintained by researchers and engineers within the [Google Brain team](https://research.google.com/teams/brain/) and a community of users. This colab shows you some datasets we have in T2T, how to download and use them, some models we have, how to download pre-trained models and use them, and how to create and train your own models."
      ]
    },
    {
      "metadata": {
        "id": "s19ucTii_wYb",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Copyright 2018 Google LLC.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9AHJ_vujZSLL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# My first trial\n",
        "\n",
        "参考ページ  \n",
        "[Tensor2Tensorを使って独自データでseq2seqしてみる](https://www.madopro.net/entry/t2t_seq2seq)\n",
        "\n",
        "[GoogleCloudPlatform/training-data-analyst](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/09_sequence/poetry.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "uLUc4q-5ZlQ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**目標: **Colab で動作するTensor2Tensor に日本語の会話セット（雑談）を読み込ませる\n",
        "  \n",
        "日本語らしい一問一答が得られるか、確認する。  "
      ]
    },
    {
      "metadata": {
        "id": "Jweg8fBlftOB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "seq2seq についての私のざっくりした理解。  \n",
        "\n",
        "\n",
        "1.   in / out に対応するsentenceのセットを用意する\n",
        "2.   in  sentence で ネットワークを作成する\n",
        "3.   out sentenceで ネットワークを作成する  \n",
        "4.  ある入力があったとき out  sentence vector が合致したものを探して返す\n",
        "\n",
        "\n",
        "  これって、世界の言語をメタ言語化するという話みたいだ。。。　　\n",
        "  \n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "KydJqxg4ZG3M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 初期処理\n"
      ]
    },
    {
      "metadata": {
        "id": "SoMoflgiZkOI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  data/train用のディレクトリなどを用意\n"
      ]
    },
    {
      "metadata": {
        "id": "ASa-N9vJNVc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "26035173-52f7-4132-e530-03ff36c49051"
      },
      "cell_type": "code",
      "source": [
        "# mount google drive to keep train data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "! mkdir -p \"./gdrive/My Drive/Colab Notebooks/T2T_my_first_trail/data\"\n",
        "! mkdir -p \"./gdrive/My Drive/Colab Notebooks/T2T_my_first_trail/train\"\n",
        "! ls \"./gdrive/My Drive/Colab Notebooks/T2T_my_first_trail\"\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "data  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ruXtXM6qZx5X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### install python package  \n"
      ]
    },
    {
      "metadata": {
        "id": "OPGni6fuvoTj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install deps\n",
        "!pip install -q -U tensor2tensor\n",
        "!pip install -q tensorflow matplotlib\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lWrMAq8EY98w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### setting environment parameters\n",
        "  \n",
        "Tensor2Tensor の README を読むと、環境変数を使っていたので。。。\n",
        "\n",
        "チュートリアルのmodel を seq2seq に変更する。 \n"
      ]
    },
    {
      "metadata": {
        "id": "k8b-712FAKjr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "# os.environ['DATA_DIR'] = '~/t2t/data'\n",
        "os.environ['DATA_DIR'] = \"./gdrive/My Drive/Colab Notebooks/T2T_my_first_trail/data\"\n",
        "os.environ['TMP_DIR']  ='~/t2t/tmp'\n",
        "# os.environ['TRAIN_DIR'] = '~/t2t/train'\n",
        "os.environ['TRAIN_DIR'] = \"./gdrive/My Drive/Colab Notebooks/T2T_my_first_trail/train\"\n",
        "\n",
        "os.environ['USR_DIR']  = '~/myproblem'\n",
        "\n",
        "os.environ['PROBLEM'] = 'my_problem'\n",
        "os.environ['MODEL']   = 'lstm_seq2seq_attention_bidirectional_encoder'\n",
        "os.environ['HPARAMS'] = 'lstm_luong_attention_multi'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4X8zXBCZ4lb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  import python packages\n",
        "\n",
        "チュートリアルの記述を流用。"
      ]
    },
    {
      "metadata": {
        "id": "tK2h2c9xzStQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "import matplotlib.pyplot as plt のところで、以下のエラーが出力される  \n",
        "\n",
        "---  \n",
        "`This call to matplotlib.use() has no effect because the backend has already   been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot, or matplotlib.backends is imported for the first time.`\n",
        "\n",
        "---\n",
        "上記エラー解決のため、セル先頭にimport matplotlibの行を追加する。  \n",
        "--> 解決しなかった。  よくわからない。  とにかく、処理は進む。  \n"
      ]
    },
    {
      "metadata": {
        "id": "oILRLCWN_16u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to avoid the warning\n",
        "#   This call to matplotlib.use() has no effect because the backend has already\n",
        "#   been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
        "#   or matplotlib.backends is imported for the first time.\n",
        "import matplotlib\n",
        "\n",
        "# Imports we need.\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import collections\n",
        "\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.layers import common_layers\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "from tensor2tensor.utils import t2t_model\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.utils import metrics\n",
        "\n",
        "# Enable TF Eager execution\n",
        "tfe = tf.contrib.eager\n",
        "tfe.enable_eager_execution()\n",
        "\n",
        "# Other setup\n",
        "Modes = tf.estimator.ModeKeys\n",
        "\n",
        "# Setup some directories\n",
        "data_dir  = os.path.expanduser(os.environ['DATA_DIR'] )\n",
        "tmp_dir   = os.path.expanduser(os.environ['TMP_DIR'] )\n",
        "train_dir = os.path.expanduser(os.environ['TRAIN_DIR'])\n",
        "usr_dir   = os.path.expanduser(os.environ['USR_DIR'])\n",
        "\n",
        "# tf.gfile.MakeDirs(data_dir)\n",
        "tf.gfile.MakeDirs(tmp_dir)\n",
        "# tf.gfile.MakeDirs(train_dir)\n",
        "tf.gfile.MakeDirs(usr_dir)\n",
        "\n",
        "gs_data_dir = \"gs://tensor2tensor-data\"\n",
        "gs_ckpt_dir = \"gs://tensor2tensor-checkpoints/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T1oJq4vJFlKj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## download conversation data  \n",
        "\n",
        "名古屋大学の公開会話データセットからデータをダウンロード\n",
        "\n",
        "https://qiita.com/knok/items/df7a155d17e3c9a12e94 のページにあるスクリプトを利用させてもらう。ありがとう、知らない人。\n"
      ]
    },
    {
      "metadata": {
        "id": "Tv46aEALcKSd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(os.path.join(data_dir, 'sequence.txt')):\n",
        "    ! git clone https://github.com/knok/make-meidai-dialogue.git\n",
        "    ! cd make-meidai-dialogue; make all\n",
        "    # 作成内容の確認\n",
        "    ! ls make-meidai-dialogue\n",
        "    ! head make-meidai-dialogue/sequence.txt\n",
        "\n",
        "    # 指定したdata directoryへデータをコピー\n",
        "    ! cp make-meidai-dialogue/sequence.txt \"${DATA_DIR}/\"\n",
        "    ! ls -ltr \"$DATA_DIR\"\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eL3ZSWJ9eVsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "bf30b760-0b3e-445e-94af-c7190eb28e7f"
      },
      "cell_type": "code",
      "source": [
        "# 作成内容の確認\n",
        "! head \"${DATA_DIR}/sequence.txt\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: ＊＊＊でも録音した方がいいじゃん。\n",
            "output: そうしましょう。\n",
            "input: そうしましょう。\n",
            "output: はい。\n",
            "input: 何？\n",
            "output: 作ってくるわ、瀬戸資料館で。\n",
            "input: もう始まってんだよね。\n",
            "output: うん、始まってる。\n",
            "input: うん、始まってる。\n",
            "output: 私もここに潜んでいていいかしら？\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nncDFhRks14S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## create my problem"
      ]
    },
    {
      "metadata": {
        "id": "Zjyphi3wZUhH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1da0538f-a802-46c1-9834-9203addb9849"
      },
      "cell_type": "code",
      "source": [
        "%%writefile ~/myproblem/myproblem.py\n",
        "import os\n",
        "import re\n",
        "\n",
        "from tensor2tensor.data_generators import problem\n",
        "from tensor2tensor.data_generators import text_problems\n",
        "from tensor2tensor.utils import registry\n",
        "\n",
        "@registry.register_problem\n",
        "class MyProblem(text_problems.Text2TextProblem):\n",
        "  \"\"\"Predict next line of poetry from the last line. From Gutenberg texts.\"\"\"\n",
        "\n",
        "  @property\n",
        "  def approx_vocab_size(self):\n",
        "    return 2**13  # ~8k\n",
        "\n",
        "  @property\n",
        "  def is_generate_per_split(self):\n",
        "    # generate_data will shard the data into TRAIN and EVAL for us.\n",
        "    return False\n",
        "\n",
        "  @property\n",
        "  def dataset_splits(self):\n",
        "    \"\"\"Splits of data to produce and number of output shards for each.\"\"\"\n",
        "    # 10% evaluation data\n",
        "    return [{\n",
        "        \"split\": problem.DatasetSplit.TRAIN,\n",
        "        \"shards\": 9,\n",
        "    }, {\n",
        "        \"split\": problem.DatasetSplit.EVAL,\n",
        "        \"shards\": 1,\n",
        "    }]\n",
        "\n",
        "\n",
        "  def generate_samples(self, data_dir, tmp_dir, dataset_split):\n",
        "    filename = os.path.join(data_dir, 'sequence.txt')\n",
        "    f = open(filename, 'r')\n",
        "    while True:\n",
        "        line1 = f.readline()\n",
        "        line2 = f.readline()\n",
        "        if not line2: break  # EOF\n",
        "\n",
        "        yield {\n",
        "            'inputs': line1.strip('input: '),\n",
        "            'targets': line2.strip('output: ')\n",
        "        }\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /root/myproblem/myproblem.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E8TUN9BfEwjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "869ce092-af4d-404a-fb8b-8805738b59a1"
      },
      "cell_type": "code",
      "source": [
        "%%writefile ~/myproblem/__init__.py\n",
        "from . import myproblem"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /root/myproblem/__init__.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RGKMeSHgHHYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "86bf0a52-b336-471d-bf61-1eb2fdc2c3d8"
      },
      "cell_type": "code",
      "source": [
        "! find ~/myproblem"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/myproblem\n",
            "/root/myproblem/myproblem.py\n",
            "/root/myproblem/__init__.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dSjs46uzTPq5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## generate dataset"
      ]
    },
    {
      "metadata": {
        "id": "u71noXoB0ab8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(os.environ['HOME'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zh3XfQ7R0hqz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from myproblem import myproblem\n",
        "\n",
        "\n",
        "# Fetch the my problem problem\n",
        "my_problem = problems.problem(\"my_problem\")\n",
        "\n",
        "if not os.path.isfile(os.path.join(data_dir, 'vocab.my_problem.8192.subwords')):\n",
        "    # The generate_data method of a problem will download data and process it into\n",
        "    # a standard format ready for training and evaluation.\n",
        "    my_problem.generate_data(data_dir, tmp_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FguMjLE3Tk4s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## train data"
      ]
    },
    {
      "metadata": {
        "id": "rSKAtxalBdHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 状況確認"
      ]
    },
    {
      "metadata": {
        "id": "uBNHRN2RuNtX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "7ee646a1-a2c3-4748-ba74-c21be52f5aa4"
      },
      "cell_type": "code",
      "source": [
        "! ls -ltr \"$DATA_DIR\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 6292\n",
            "-rw------- 1 root root 3720966 Oct  5 08:08 sequence.txt\n",
            "-rw------- 1 root root   85688 Oct  5 08:12 vocab.my_problem.8192.subwords\n",
            "-rw------- 1 root root  262423 Oct  5 08:12 my_problem-train-00008-of-00009\n",
            "-rw------- 1 root root  263787 Oct  5 08:12 my_problem-train-00007-of-00009\n",
            "-rw------- 1 root root  264467 Oct  5 08:12 my_problem-train-00006-of-00009\n",
            "-rw------- 1 root root  262788 Oct  5 08:12 my_problem-train-00005-of-00009\n",
            "-rw------- 1 root root  262585 Oct  5 08:12 my_problem-train-00004-of-00009\n",
            "-rw------- 1 root root  264082 Oct  5 08:12 my_problem-train-00003-of-00009\n",
            "-rw------- 1 root root  262037 Oct  5 08:12 my_problem-train-00002-of-00009\n",
            "-rw------- 1 root root  263995 Oct  5 08:12 my_problem-train-00001-of-00009\n",
            "-rw------- 1 root root  262837 Oct  5 08:12 my_problem-train-00000-of-00009\n",
            "-rw------- 1 root root  263875 Oct  5 08:12 my_problem-dev-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "arofRSCCpp_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5b80aebb-9044-4011-93c6-4ea7defee98e"
      },
      "cell_type": "code",
      "source": [
        "# Fetch the problem\n",
        "my_problem = problems.problem(\"my_problem\")\n",
        "\n",
        "# Copy the vocab file locally so we can encode inputs and decode model outputs\n",
        "# All vocabs are stored on GCS\n",
        "vocab_name = \"vocab.my_problem.8192.subwords\"\n",
        "vocab_file = os.path.join(data_dir, vocab_name)\n",
        "print(vocab_file)\n",
        "!head \"{vocab_file}\"\n",
        "\n",
        "# Get the encoders from the problem\n",
        "encoders = my_problem.feature_encoders(data_dir)\n",
        "\n",
        "# Setup helper functions for encoding and decoding\n",
        "def encode(input_str, output_str=None):\n",
        "  \"\"\"Input str to features dict, ready for inference\"\"\"\n",
        "  inputs = encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
        "  batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
        "  return {\"inputs\": batch_inputs}\n",
        "\n",
        "def decode(integers):\n",
        "  \"\"\"List of ints to str\"\"\"\n",
        "  integers = list(np.squeeze(integers))\n",
        "  if 1 in integers:\n",
        "    integers = integers[:integers.index(1)]\n",
        "  return encoders[\"inputs\"].decode(np.squeeze(integers))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./gdrive/My Drive/Colab Notebooks/T2T_my_first_trail/data/vocab.my_problem.8192.subwords\n",
            "'<pad>_'\n",
            "'<EOS>_'\n",
            "'、_'\n",
            "'。\\10;_'\n",
            "'_'\n",
            "'うん_'\n",
            "'？\\10;_'\n",
            "'）_'\n",
            "'、（_'\n",
            "'ね_'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ujuI67OCAWbf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 日本語も分かち書きされて、IDが振られているみたいだ。  "
      ]
    },
    {
      "metadata": {
        "id": "o1-gNpAYvCmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "1ca0a14e-39d9-4744-dd50-3ed57747a518"
      },
      "cell_type": "code",
      "source": [
        "# Generate and view the data\n",
        "\n",
        "example = tfe.Iterator(my_problem.dataset(Modes.TRAIN, data_dir)).next()\n",
        "inputs = [int(x) for x in example[\"inputs\"].numpy()] # Cast to ints.\n",
        "targets = [int(x) for x in example[\"targets\"].numpy()] # Cast to ints.\n",
        "\n",
        "\n",
        "# Example inputs as int-tensor.\n",
        "print(\"Inputs, encoded:\")\n",
        "print(inputs)\n",
        "print(\"Inputs, decoded:\")\n",
        "# Example inputs as a sentence.\n",
        "print(decode(inputs))\n",
        "# Example targets as int-tensor.\n",
        "print(\"Targets, encoded:\")\n",
        "print(targets)\n",
        "# Example targets as a sentence.\n",
        "print(\"Targets, decoded:\")\n",
        "print(decode(targets))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reading data files from ./gdrive/My Drive/Colab Notebooks/T2T_my_first_trail/data/my_problem-train*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 9\n",
            "Inputs, encoded:\n",
            "[19, 2, 761, 604, 1609, 4044, 821, 12, 2, 5, 3, 1]\n",
            "Inputs, decoded:\n",
            "そう、機内持ち込みにしてー、うん。\n",
            "\n",
            "Targets, encoded:\n",
            "[5224, 24, 3874, 66, 3, 1]\n",
            "Targets, decoded:\n",
            "そっちの方が迷惑じゃん。\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tZITcI7AB1yR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### t2t-trainer"
      ]
    },
    {
      "metadata": {
        "id": "tFapfE8WAtfI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "t2t-trainerコマンドだが、とても、時間がかかる。\n",
        "ホスト側から、処理キャンセルされてしまう。  \n",
        "  \n",
        "そのため、train data directory をgoogle driveに割り当て、google collabolationからセッション切断されても、トレーニングを再開できるようにする。  \n"
      ]
    },
    {
      "metadata": {
        "id": "0u6QtS4UXB2Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "25000 steps がdefaultのようなのだが、たぶん、半日経過しても終了しないし、その前にセッションを切断される。  \n",
        "中断されたら、またこのセルを実行する。  \n",
        "250K steps のトレーニングがいつ終了するのか、誰も知らない。"
      ]
    },
    {
      "metadata": {
        "id": "T66rZPI27Jkz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#! t2t-trainer \\\n",
        "#  --data_dir=$DATA_DIR \\\n",
        "#  --t2t_usr_dir=$USR_DIR \\\n",
        "#  --problem=$PROBLEM \\\n",
        "#  --model=$MODEL \\\n",
        "#  --hparams_set=$HPARAMS \\\n",
        "#  --output_dir=$TRAIN_DIR\n",
        "\n",
        "! t2t-trainer \\\n",
        "  --data_dir=\"$DATA_DIR\" \\\n",
        "  --t2t_usr_dir=\"$USR_DIR\" \\\n",
        "  --problem=\"$PROBLEM\" \\\n",
        "  --model=\"$MODEL\" \\\n",
        "  --hparams_set=\"$HPARAMS\" \\\n",
        "  --output_dir=\"$TRAIN_DIR\" \\\n",
        "  --keep_checkpoint_max=3 \\\n",
        "  --keep_checkpoint_every_n_hours=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15bH27QnKqSK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls -ltr  \"$TRAIN_DIR\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2cuo9PPEevV8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "途中で終わったにせよ、trainデータがあるので、様子を見てみる。  \n"
      ]
    },
    {
      "metadata": {
        "id": "Ucl9UOHpFmkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# BEAM_SIZE=4\n",
        "# ALPHA=0.6\n",
        "! t2t-decoder \\\n",
        "   --data_dir=\"$DATA_DIR\" \\\n",
        "   --problem=$PROBLEM \\\n",
        "   --model=$MODEL \\\n",
        "   --hparams_set=$HPARAMS \\\n",
        "   --output_dir=\"$TRAIN_DIR\" \\\n",
        "   --decode_hparams=\"beam_size=4,alpha=0.6\" \\\n",
        "   --decode_interactive=true \\\n",
        "   --t2t_usr_dir=\"$USR_DIR\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_J7cSNwEXLhk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習が進んでいないせいか、何を聞いても「うん」としか答えない。  \n",
        "学習が進めば、もう少し、賢くなりそうなのだが。。。  \n"
      ]
    },
    {
      "metadata": {
        "id": "sO4N-cvCiO52",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "70000 stepsぐらいのトレーニングで、「うん」以外の答えがでるようになった。たいへんだ。\n",
        "\n",
        "\n",
        "```\n",
        ">おはよう、世界\n",
        "INFO:tensorflow:うん。\n",
        "\n",
        ">今日は暑いね\n",
        "INFO:tensorflow:気出ないよ。\n",
        "\n",
        ">なにか、おもしろいことあった？\n",
        "INFO:tensorflow:はいはい、はい。\n",
        "\n",
        ">「うん」以外云えないの？\n",
        "INFO:tensorflow:そうそうそう。\n",
        "\n",
        "```\n",
        "\n"
      ]
    }
  ]
}